```python
# -*- coding: UTF-8 -*-
import sqlite3
import sys
import threading
import time
from datetime import datetime

import requests
import urllib3
import os
import lxml
from bs4 import BeautifulSoup
import logging

exec_path = os.path.dirname(str(sys.argv[0]))
local_dir_path = exec_path.replace('/', os.path.sep)
urllib3.disable_warnings()

############# Log setting ################
now = datetime.now()
date_str = now.strftime("%Y-%m-%d_%H-%M-%S")
log_folder_name = local_dir_path + "\\logs"
os.makedirs(log_folder_name, exist_ok=True)
logging.basicConfig(format='%(asctime)s:%(levelname)s:%(threadName)s:%(process)d:%(funcName)s:%(message)s',
                    level=logging.INFO,
                    filename=f"{log_folder_name}/log_{date_str}.log",
                    encoding='utf-8')
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


proxies = {
        "http": "http://10.23.29.130:8080",
        "https": "http://10.23.29.130:8080",
        "no_proxy": None
    }


def jinzhou_maize(url: str) -> str:
    headers = {
        'Accept-Ranges': 'bytes',
        'Connection': 'keep-alive',
        'Content-Security-Policy': 'default-src * \'unsafe - eval\' \'unsafe - inline\';',
        'Content-Type': 'text/html',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                      'Chrome/112.0.0.0 Safari/537.36',
        'X-Requested-With': 'XMLHttpRequest',
    }
    retry_counts = 3
    while True:
        if retry_counts <= 0:
            logger.error("max retry counts exceed")
            return ""
        try:
            time.sleep(3)
            response = requests.post(url=url, headers=headers, proxies=None, verify=False)
            logger.info("request for {}, headers: {}, proxies: {}".format(url, headers, None))
            if response.status_code == 200:
                response.encoding = 'UTF-8'
                # print(response.text)
                soup = BeautifulSoup(response.text, 'lxml')
                print(soup)
                # time_span = soup.find('div', {'class': 'san-col-4 san-col-m-6 AC-xl AC-l'}).findAll("span")[0]
                # print(time_span.text)
                # return time_span.text.strip()
                return ""
            else:
                retry_counts -= 1
                logger.error("error return code: {}".format(response.status_code))
                continue
        except Exception as e:
            retry_counts -= 1
            logger.error("exception: {}".format(e))
            continue


def get_one(start, end):
    for page in range(start, end+1):
        url = f"https://www.100ppi.com/mprice/detail-{page}.html"
        headers = {
            'Accept-Ranges': 'bytes',
            'Connection': 'keep-alive',
            'Content-Security-Policy': 'default-src * \'unsafe - eval\' \'unsafe - inline\';',
            'Content-Type': 'text/html',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '
                          'Chrome/112.0.0.0 Safari/537.36',
            'X-Requested-With': 'XMLHttpRequest',
        }
        try:
            conn, cur = create_table()
            response = requests.get(url,  headers=headers, proxies=None, verify=False)
            if response.status_code == 200:
                html = response.text
                # 用beautifulsoup解析html
                soup = BeautifulSoup(html, "html.parser")

                div = soup.find('div', class_='location')
                text = div.get_text()
                category = text.split('>')[-1].strip()
                table = soup.find("table", class_="st2-table tac")  # 找到表格
                rows = table.find_all("tr")  # 找到所有的行
                data = []  # 用来存储数据的列表
                for row in rows:
                    cells = row.find_all(["th", "td"])  # 找到所有的单元格
                    values = [cell.get_text().strip() for cell in cells]  # 获取单元格的文本
                    data.append(values)  # 把值添加到数据列表
                company = data[0][1].split(" ")[0].strip()  # 公司名称
                tax_price = data[1][1].strip()  # 含税价格
                delivery_place = data[1][3].strip()  # 交货地
                price_type = data[2][1].strip()  # 报价类型
                package = data[2][3].strip()  # 包装
                origin_or_brand = data[3][1].strip()  # 产地或品牌
                publish_time = data[3][3].strip()  # 发布时间
                attribute_spec = data[4][1].strip()  # 属性规格
                logger.info(f"url: {url}, category: {category}, data: {data}")
                # 插入数据
                cur.execute("""INSERT INTO prices VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""", (category, company,
                                                                                             tax_price, delivery_place,
                                                                                             price_type, package,
                                                                                             origin_or_brand,
                                                                                             publish_time,
                                                                                             attribute_spec, url))
                # 提交更改
                conn.commit()
                time.sleep(1)
            else:
                logger.error(f"return code: {response.status_code}")
        except Exception as e:
            logger.error(f"Exception: {e}")


def create_table():
    # 连接sqlite3数据库
    conn = sqlite3.connect("data.db")  # 创建或打开数据库文件
    cur = conn.cursor()
    # 创建数据表
    cur.execute("""CREATE TABLE IF NOT EXISTS prices (
            category TEXT,
            company TEXT,
            tax_price TEXT,
            delivery_place TEXT,
            price_type TEXT,
            package TEXT,
            origin_or_brand TEXT,
            publish_time TEXT,
            attribute_spec TEXT,
            url TEXT
        )""")
    return conn, cur


def main():
    # 创建一个空列表，用来存储线程对象
    threads = []
    # 定义总数据量
    init_start = 1
    init_end = 1000000
    # 定义线程数量
    num = 100
    # 计算每个线程处理的数据量
    size = (init_end - init_start) // num
    # 创建32个线程，传递不同的参数
    for i in range(num):
        # 计算每个线程的开始和结束位置
        start = i * size + 1 + init_start if i > 0 else init_start
        end = (i + 1) * size + init_start if i < num - 1 else init_end
        print(i, start, end)
        # 创建一个线程对象，指定目标函数和参数，以及线程名
        t = threading.Thread(target=get_one, args=(start, end), name=str(i + 1))
        # 把线程对象添加到线程列表中
        threads.append(t)
        # 启动线程
        t.start()
    # 等待所有线程结束
    for t in threads:
        # join方法会等待线程结束
        t.join()


if __name__ == '__main__':
    main()

```